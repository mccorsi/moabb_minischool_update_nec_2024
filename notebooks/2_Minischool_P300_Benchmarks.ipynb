{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30338bd2",
   "metadata": {},
   "source": [
    "# Comparison of multiple pipelines and datasets with P300\n",
    "\n",
    "In this second notebook, we will use P300 paradigm to compare multiple datasets and multiple pipelines. We choose datasets from the BNCI repository.\n",
    "\n",
    "Please make sure you have verified your installation with the notebook `0_Minischool_Verify_Installation`.\n",
    "\n",
    "## Selecting datasets\n",
    "\n",
    "The datasets already defined in MOABB are listed in the [documentation](https://neurotechx.github.io/moabb/api.html). It is also possible to check the [MOABB wiki](https://github.com/NeuroTechX/moabb/wiki/Datasets-Support) for comparative information.\n",
    "\n",
    "Here we will use two P300 datasets from BNCI:"
   ]
  },
  {
   "cell_type": "code",
   "id": "dda67c05",
   "metadata": {},
   "source": [
    "from moabb.datasets import BNCI2014_008, BNCI2014_009\n",
    "\n",
    "datasets = [BNCI2014_008(), BNCI2014_009()] "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae0cee04",
   "metadata": {},
   "source": [
    "from pyriemann.classification import MDM\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.spatialfilters import Xdawn\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "pipelines = {}\n",
    "pipelines['tgsp+svm'] = make_pipeline(XdawnCovariances(estimator='lwf'), \n",
    "                                      TangentSpace(metric='riemann'), \n",
    "                                      SVC(kernel='linear'))\n",
    "pipelines['MDM'] = make_pipeline(XdawnCovariances(estimator='lwf'),\n",
    "                            MDM(metric='riemann', n_jobs=-1))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9c99af4",
   "metadata": {},
   "source": [
    "from moabb.paradigms import P300\n",
    "\n",
    "paradigm = P300()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d3ba03db",
   "metadata": {},
   "source": [
    "from moabb.evaluations import WithinSessionEvaluation\n",
    "\n",
    "evaluation = WithinSessionEvaluation(paradigm=paradigm, datasets=datasets, overwrite=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae9e612f",
   "metadata": {},
   "source": [
    "results = evaluation.process(pipelines) "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "afce1471",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "\n",
    "g = sns.catplot(kind=\"box\", x=\"score\", y=\"pipeline\", col=\"dataset\", aspect=1.5, data=results, orient='h', palette='viridis')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "36973a35",
   "metadata": {},
   "source": [
    "Until now, we have always plotted the results using the seaborn package and creating the figure by ourselves. MOABB also offers some functionalities for analysing the results obtained after running an evaluation procedure.\n",
    "\n",
    "# Advanced statistical analysis and meta-analysis\n",
    "\n",
    "For instance, we may create a plot comparing the results with two classification algorithms as in:"
   ]
  },
  {
   "cell_type": "code",
   "id": "fa85a8f7",
   "metadata": {},
   "source": [
    "from moabb.analysis.plotting import paired_plot\n",
    "\n",
    "alg1 = 'tgsp+svm'\n",
    "alg2 = 'MDM'\n",
    "fig = paired_plot(results, alg1, alg2)\n",
    "fig.set_size_inches(9,9)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "374ad472",
   "metadata": {},
   "source": [
    "N.B.: MOABB collapses the values from different sessions into a single average score, which is why we have the impression of having much less points than it should in the plot.\n",
    "\n",
    "We may also do statistical analysis on the results and plot them with MOABB. For this, we need to first generate an auxiliary dataframe containing all the statistics describing the results and, then, use it as input."
   ]
  },
  {
   "cell_type": "code",
   "id": "a02441da",
   "metadata": {},
   "source": [
    "from moabb.analysis.meta_analysis import compute_dataset_statistics\n",
    "from moabb.analysis.plotting import meta_analysis_plot\n",
    "\n",
    "stats_df = compute_dataset_statistics(results)\n",
    "alg1 = 'tgsp+svm'\n",
    "alg2 = 'MDM'\n",
    "fig = meta_analysis_plot(stats_df, alg1, alg2)\n",
    "fig.set_size_inches(6, 5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22d81a34",
   "metadata": {},
   "source": [
    "from moabb.analysis.meta_analysis import find_significant_differences\n",
    "from moabb.analysis.plotting import summary_plot\n",
    "\n",
    "P, T = find_significant_differences(stats_df)\n",
    "_ = summary_plot(P, T)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "33015804",
   "metadata": {},
   "source": [
    "# Adapting MOABB to your need\n",
    "\n",
    "Here are some exercices to introduce some useful possibilities offered by MOABB. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac11658",
   "metadata": {},
   "source": [
    "## Add new datasets in the evaluation (level: easy ðŸ¤—)\n",
    "\n",
    "Use the code above to add another dataset in your evaluation"
   ]
  },
  {
   "cell_type": "code",
   "id": "a3cf2aa7",
   "metadata": {},
   "source": [
    "from moabb.datasets import BNCI2015_003\n",
    "\n",
    "datasets = [BNCI2014_008(), BNCI2014_009(), BNCI2015_003()]\n",
    "paradigm = P300()\n",
    "evaluation = WithinSessionEvaluation(paradigm=paradigm, datasets=datasets, overwrite=False)\n",
    "\n",
    "results = evaluation.process(pipelines)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a853120d",
   "metadata": {},
   "source": [
    "## Creating your own pipeline (level: intermediate ðŸ¤”)\n",
    "\n",
    "The first is to create your machine learning pipeline, according to your need. As MOABB use a sklearn-like API for defining pipelines, it is easy to follow the [sklearn tutorial](https://scikit-learn.org/stable/developers/develop.html)"
   ]
  },
  {
   "cell_type": "code",
   "id": "9450f11c",
   "metadata": {},
   "source": [
    "from mne.decoding import Vectorizer\n",
    "\n",
    "labels_dict = {\"Target\": 1, \"NonTarget\": 0}\n",
    "\n",
    "your_pipelines = {}\n",
    "your_pipelines[\"RG+LDA\"] = make_pipeline(\n",
    "    XdawnCovariances(\n",
    "        nfilter=2, classes=[labels_dict[\"Target\"]], estimator=\"lwf\", xdawn_estimator=\"scm\"\n",
    "    ),\n",
    "    TangentSpace(),\n",
    "    LDA(solver=\"lsqr\", shrinkage=\"auto\"),\n",
    ")\n",
    "\n",
    "your_pipelines[\"Xdw+LDA\"] = make_pipeline(\n",
    "    Xdawn(nfilter=2, estimator=\"scm\"), Vectorizer(), LDA(solver=\"lsqr\", shrinkage=\"auto\")\n",
    ")\n",
    "\n",
    "paradigm = P300(resample=128)\n",
    "\n",
    "dataset = BNCI2014_009()\n",
    "dataset.subject_list = dataset.subject_list[:2]\n",
    "datasets = [dataset]\n",
    "overwrite = True  # set to True if we want to overwrite cached results\n",
    "\n",
    "evaluation = WithinSessionEvaluation(\n",
    "    paradigm=paradigm, datasets=datasets, suffix=\"examples\", overwrite=overwrite\n",
    ")\n",
    "\n",
    "results = evaluation.process(your_pipelines)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "12132e86",
   "metadata": {},
   "source": [
    "## Use learning curve (level intermediate ðŸ¤”)\n",
    "\n",
    "Based on the example from the [MOABB gallery](https://neurotechx.github.io/moabb/auto_examples/index.html#evaluation-with-learning-curve) and the [documentation](https://neurotechx.github.io/moabb/generated/moabb.evaluations.WithinSessionEvaluation.html#moabb.evaluations.WithinSessionEvaluation), create an evaluation with an increasing number of sample. For example, using only 1%, 5% and 10% of the data to train. "
   ]
  },
  {
   "cell_type": "code",
   "id": "1393cf5d",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "your_pipelines = {}\n",
    "your_pipelines[\"RG+LDA\"] = make_pipeline(\n",
    "    XdawnCovariances(\n",
    "        nfilter=2, classes=[labels_dict[\"Target\"]], estimator=\"lwf\", xdawn_estimator=\"scm\"\n",
    "    ),\n",
    "    TangentSpace(),\n",
    "    LDA(solver=\"lsqr\", shrinkage=\"auto\"),\n",
    ")\n",
    "\n",
    "your_pipelines[\"Xdw+LDA\"] = make_pipeline(\n",
    "    Xdawn(nfilter=2, estimator=\"scm\"), Vectorizer(), LDA(solver=\"lsqr\", shrinkage=\"auto\")\n",
    ")\n",
    "\n",
    "paradigm = P300(resample=128)\n",
    "\n",
    "dataset = BNCI2014_009()\n",
    "dataset.subject_list = dataset.subject_list[:2]\n",
    "datasets = [dataset]\n",
    "overwrite = True  # set to True if we want to overwrite cached results\n",
    "data_size = dict(policy=\"ratio\", value=[0.01, 0.05, 0.1])\n",
    "# When the training data is sparse, perform more permutations than when we have a lot of data\n",
    "n_perms = np.floor(np.geomspace(20, 2, len(data_size[\"value\"]))).astype(int)\n",
    "np.random.seed(7536298)\n",
    "\n",
    "evaluation = WithinSessionEvaluation(\n",
    "    paradigm=paradigm, datasets=datasets, suffix=\"examples\", overwrite=overwrite, data_size=data_size,n_perms=n_perms,\n",
    ")\n",
    "\n",
    "results = evaluation.process(your_pipelines)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(facecolor=\"white\", figsize=[8, 4])\n",
    "\n",
    "n_subs = len(dataset.subject_list)\n",
    "\n",
    "if n_subs > 1:\n",
    "    r = results.groupby([\"pipeline\", \"subject\", \"data_size\"]).mean().reset_index()\n",
    "else:\n",
    "    r = results\n",
    "\n",
    "sns.pointplot(data=r, x=\"data_size\", y=\"score\", hue=\"pipeline\", ax=ax, palette=\"Set1\")\n",
    "\n",
    "errbar_meaning = \"subjects\" if n_subs > 1 else \"permutations\"\n",
    "title_str = f\"Errorbar shows Mean-CI across {errbar_meaning}\"\n",
    "ax.set_xlabel(\"Amount of training samples\")\n",
    "ax.set_ylabel(\"ROC AUC\")\n",
    "ax.set_title(title_str)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "id": "eec0928b40f86b6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1d7c1941e87115ac",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
